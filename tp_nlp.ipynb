{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOirxDoqeiZMCAC2qTeZJvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agustin-Galarza/tp_nlp/blob/main/tp_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "d1hHf-GXpuJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "Ek8dP5DO-Igh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "from typing import Dict, List, Optional, Iterable\n",
        "from pandas import DataFrame\n",
        "from enum import Enum\n",
        "import sys"
      ],
      "metadata": {
        "id": "EY4eLXqfppZq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get credentials to acces the drive folder"
      ],
      "metadata": {
        "id": "ovlYOc249dFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "Lw1yVbk4-Guk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read file and store all the parsed programs"
      ],
      "metadata": {
        "id": "LQ3WjTJU9ick"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPOS_TO_SCAN = -1\n",
        "FILES_PER_REPO = -1\n",
        "datadir = \"./sample_data\"\n",
        "filename = \"test_data.json\"\n",
        "\n",
        "files: List[List[str]] = []\n",
        "with open(f\"{datadir}/{filename}\") as dataset:\n",
        "    for line_no, line in enumerate(dataset):\n",
        "        if REPOS_TO_SCAN != -1 and line_no == REPOS_TO_SCAN:\n",
        "            break\n",
        "        repository = json.loads(line)\n",
        "        filesdata: Dict = repository.get(\"filedata\")\n",
        "        for i, file in enumerate(filesdata.values()):\n",
        "            if FILES_PER_REPO != -1 and i == FILES_PER_REPO:\n",
        "                break\n",
        "            tokens = file.get(\"tokens\")\n",
        "            files.append(tokens)"
      ],
      "metadata": {
        "id": "X7EOAMnGtNIr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function and type definitions"
      ],
      "metadata": {
        "id": "VNl7O38j91FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FunctionData:\n",
        "    name: str\n",
        "    params: List[str]\n",
        "    block: List[str]\n",
        "\n",
        "    def copy(self) -> \"FunctionData\":\n",
        "        return FunctionData(self.name[:], self.params[:], self.block[:])\n",
        "\n",
        "\n",
        "class ParametersParsingData:\n",
        "    is_type_def = False\n",
        "    braces: List[str] = []\n",
        "    sharp_braces: List[str] = []\n",
        "    parenthesis: List[str] = []\n",
        "\n",
        "\n",
        "class BlockParsingData:\n",
        "    braces: List[str] = []\n",
        "\n",
        "\n",
        "class ReturnTypeData:\n",
        "    containers: int = 0\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.tokens_len = len(tokens)\n",
        "        self.current_index = 0\n",
        "        self.marker = 0\n",
        "\n",
        "    def current_token(self) -> Optional[str]:\n",
        "        return (\n",
        "            self.tokens[self.current_index]\n",
        "            if self.current_index < self.tokens_len\n",
        "            else None\n",
        "        )\n",
        "\n",
        "    def consume_token(self) -> Optional[str]:\n",
        "        current_token = self.current_token()\n",
        "        self.current_index += 1\n",
        "        return current_token\n",
        "\n",
        "    def is_current_token(self, token: str) -> bool:\n",
        "        current = self.current_token()\n",
        "        return current == token\n",
        "\n",
        "    def set_marker(self) -> None:\n",
        "        \"\"\"Sets the marker to the current position\"\"\"\n",
        "        self.marker = self.current_index\n",
        "\n",
        "    def from_marker_to(self, n: int) -> List[str]:\n",
        "        \"\"\"Returns the list of tokens from the marked up to n tokens forward\"\"\"\n",
        "        if n < 0:\n",
        "            raise ValueError(f\"n must be positive but is {n}\")\n",
        "        return self.tokens[self.marker : self.marker + n + 1]\n",
        "\n",
        "    def from_marker_to_current(self) -> List[str]:\n",
        "        \"\"\"Returns the list of tokens from the marked token to the current token\"\"\"\n",
        "        return self.tokens[self.marker : self.current_index + 1]\n",
        "\n",
        "\n",
        "class State(Enum):\n",
        "    Start = \"Start\"\n",
        "    End = \"End\"\n",
        "    Error = \"Error\"\n",
        "    FunctionName = \"FunctionName\"\n",
        "    FunctionGeneric = \"FunctionGeneric\"\n",
        "    Parameters = \"Parameters\"\n",
        "    ParseParameter = \"ParseParameter\"\n",
        "    ReturnType = \"ReturnType\"\n",
        "    ParseReturnType = \"ParseReturnType\"\n",
        "    FunctionBlock = \"FunctionBlock\"\n",
        "    ParseBlockContent = \"ParseBlockContent\"\n",
        "\n",
        "    def is_end_state(self, state: \"State\") -> bool:\n",
        "        return [State.End, State.Error] in state\n",
        "\n",
        "\n",
        "class FunctionParser:\n",
        "    def __init__(self, file, error_file=sys.stderr):\n",
        "        self.tokens = file\n",
        "        self.functions: List[FunctionData] = []\n",
        "        self.error_file = error_file\n",
        "\n",
        "    def __invalid_function_name(self, name: str) -> bool:\n",
        "        invalid_chars_in_name = set(\"{}()<>\")\n",
        "        return any((c in invalid_chars_in_name) for c in name)\n",
        "\n",
        "    def __build_err_msg_for_function(\n",
        "        self, title: str, tokenizer: Tokenizer, fn_data: FunctionData\n",
        "    ) -> None:\n",
        "        self.error_msg = f\"\"\"\n",
        "            {title}\n",
        "            raw: {\" \".join(tokenizer.from_marker_to(150))}\n",
        "            current: {\" \".join(tokenizer.from_marker_to_current())}\n",
        "            name: {fn_data.name}\n",
        "            params: {fn_data.params}\n",
        "            block: {fn_data.block}\n",
        "            ====================================================================================================================\n",
        "            \"\"\"\n",
        "\n",
        "    def parse(self) -> List[FunctionData]:\n",
        "        tokenizer = Tokenizer(self.tokens)\n",
        "        state = State.Start\n",
        "        current_function = FunctionData(None, [], [])\n",
        "        self.block_state = BlockParsingData()\n",
        "        print(\"Parsing\")\n",
        "\n",
        "        while tokenizer.current_token() is not None and state is not State.Error:\n",
        "            if state == State.Start:\n",
        "                token = tokenizer.consume_token()\n",
        "                if token == \"function\":\n",
        "                    print(\"function found\")\n",
        "                    tokenizer.set_marker()\n",
        "                    state = State.FunctionName\n",
        "\n",
        "            elif state == State.FunctionName:\n",
        "                function_name = tokenizer.current_token()\n",
        "                if self.__invalid_function_name(function_name):\n",
        "                    function_name = \"anonymous\"\n",
        "                else:\n",
        "                    tokenizer.consume_token()\n",
        "                print(\"function name: \" + function_name)\n",
        "                state = (\n",
        "                    State.FunctionGeneric\n",
        "                    if tokenizer.is_current_token(\"<\")\n",
        "                    else State.Parameters\n",
        "                )\n",
        "                # Clear current function data to load new\n",
        "                current_function.name = function_name\n",
        "                current_function.params.clear()\n",
        "                current_function.block.clear()\n",
        "\n",
        "            elif state == State.FunctionGeneric:\n",
        "                print(\"Generic found\")\n",
        "                # Ignore function type declaration\n",
        "                while not tokenizer.is_current_token(\">\"):\n",
        "                    tokenizer.consume_token()\n",
        "                tokenizer.consume_token()\n",
        "                state = State.Parameters\n",
        "\n",
        "            elif state == State.Parameters:\n",
        "                print(\"Parsing parameters\")\n",
        "                if not tokenizer.is_current_token(\"(\"):\n",
        "                    self.error_msg = self.__build_err_msg_for_function(\n",
        "                        \"Unrecongnized token for Parameters\",\n",
        "                        tokenizer,\n",
        "                        current_function,\n",
        "                    )\n",
        "                    state = State.Error\n",
        "                    continue\n",
        "                self.params_state = ParametersParsingData()\n",
        "                state = State.ParseParameter\n",
        "\n",
        "            elif state == State.ParseParameter:\n",
        "                token: str = tokenizer.consume_token()\n",
        "\n",
        "                if token == \"(\":\n",
        "                    self.params_state.parenthesis.append(token)\n",
        "                elif token == \")\":\n",
        "                    if len(self.params_state.parenthesis) == 0:\n",
        "                        self.__build_err_msg_for_function(\n",
        "                            \"Bad Parenthesis\", tokenizer, current_function\n",
        "                        )\n",
        "                        state = State.Error\n",
        "                        continue\n",
        "                    self.params_state.parenthesis.pop()\n",
        "                    if len(self.params_state.parenthesis) == 0:\n",
        "                        print(\"End of parameters section\")\n",
        "                        print(\"Params: \", \", \".join(current_function.params))\n",
        "                        state = State.FunctionBlock\n",
        "                        continue\n",
        "\n",
        "                elif self.params_state.is_type_def:\n",
        "                    if token == \"{\":\n",
        "                        self.params_state.braces.append(token)\n",
        "                    elif token == \"}\":\n",
        "                        self.params_state.braces.pop()\n",
        "                    elif token == \"<\":\n",
        "                        self.params_state.sharp_braces.append(token)\n",
        "                    elif token == \">\":\n",
        "                        self.params_state.sharp_braces.pop()\n",
        "                    elif (\n",
        "                        token == \",\"\n",
        "                        and len(self.params_state.braces) == 0\n",
        "                        and len(self.params_state.sharp_braces) == 0\n",
        "                    ):\n",
        "                        self.params_state.is_type_def = False\n",
        "                else:\n",
        "                    if token == \":\":\n",
        "                        print(\"parameter type found\")\n",
        "                        self.params_state.is_type_def = True\n",
        "                    elif token != \",\" and token != \"{\" and token != \"}\":\n",
        "                        print(\"Parameter found: \" + token)\n",
        "                        current_function.params.append(token)\n",
        "\n",
        "            elif state == State.ReturnType:\n",
        "                print(\"Parsing function return type\")\n",
        "                self.return_type_data = ReturnTypeData()\n",
        "                if tokenizer.is_current_token(\"{\"):\n",
        "                    print(\"Return type starts with '{'\")\n",
        "                    self.return_type_data.containers += 1\n",
        "                    tokenizer.consume_token()\n",
        "                state = State.ParseReturnType\n",
        "\n",
        "            elif state == State.ParseReturnType:\n",
        "                while True:\n",
        "                    token = tokenizer.current_token()\n",
        "                    if token == \"{\":\n",
        "                        if self.return_type_data.containers == 0:\n",
        "                            break\n",
        "                        self.return_type_data.containers += 1\n",
        "                    elif token in [\"(\", \"[\", \"<\"]:\n",
        "                        self.return_type_data.containers += 1\n",
        "                    elif token in [\")\", \"]\", \">\", \"}\"]:\n",
        "                        self.return_type_data.containers -= 1\n",
        "\n",
        "                    tokenizer.consume_token()\n",
        "\n",
        "                state = State.FunctionBlock\n",
        "\n",
        "            elif state == State.FunctionBlock:\n",
        "                print(\"Function block\")\n",
        "                if tokenizer.is_current_token(\";\"):\n",
        "                    print(\"Is function call\")\n",
        "                    # Is a function call\n",
        "                    current_function = None\n",
        "                    state = State.End\n",
        "                elif tokenizer.is_current_token(\":\"):\n",
        "                    tokenizer.consume_token()\n",
        "                    state = State.ReturnType\n",
        "                elif not tokenizer.is_current_token(\"{\"):\n",
        "                    self.__build_err_msg_for_function(\n",
        "                        \"Unrecognized token for Function Block\",\n",
        "                        tokenizer,\n",
        "                        current_function,\n",
        "                    )\n",
        "                    state = State.Error\n",
        "                else:\n",
        "                    self.block_state = BlockParsingData()\n",
        "                    state = State.ParseBlockContent\n",
        "\n",
        "            elif state == State.ParseBlockContent:\n",
        "                token = tokenizer.consume_token()\n",
        "                current_function.block.append(token)\n",
        "\n",
        "                if token == \"{\" or token.startswith(\"{\"):\n",
        "                    self.block_state.braces.append(token)\n",
        "                elif token == \"}\" or token.endswith(\"}\"):\n",
        "                    if len(self.block_state.braces) == 0:\n",
        "                        self.__build_err_msg_for_function(\n",
        "                            \"Bad Program\", tokenizer, current_function\n",
        "                        )\n",
        "                        state = State.Error\n",
        "                        continue\n",
        "                    self.block_state.braces.pop()\n",
        "                    if len(self.block_state.braces) == 0:\n",
        "                        state = State.End\n",
        "            elif state == State.End:\n",
        "                self.functions.append(current_function)\n",
        "                state = State.Start\n",
        "\n",
        "        if state not in [State.Start, State.End, State.Error]:\n",
        "            self.__build_err_msg_for_function(\n",
        "                \"Reached end of file wihtout completion\", tokenizer, current_function\n",
        "            )\n",
        "            state = State.Error\n",
        "\n",
        "        if state is State.Error:\n",
        "            if self.error_msg is None:\n",
        "                self.__build_err_msg_for_function(\n",
        "                    \"Unknown error\", tokenizer, current_function\n",
        "                )\n",
        "\n",
        "            print(self.error_msg, file=self.error_file)\n",
        "\n",
        "        return self.functions\n",
        "\n",
        "\n",
        "def extract_functions(\n",
        "    tokens_list: Iterable[List[str]],\n",
        ") -> List[FunctionData]:\n",
        "    functions: List[FunctionData] = []\n",
        "    error_file = open(\"./errors.log\", \"a+\")\n",
        "    error_file.truncate(0)\n",
        "    for tokens in tokens_list:\n",
        "        parser = FunctionParser(tokens, error_file)\n",
        "        functions.extend(parser.parse())\n",
        "    error_file.close()\n",
        "    return [fn for fn in functions if fn is not None]\n"
      ],
      "metadata": {
        "id": "sxA0MdjXpqkR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulate Data"
      ],
      "metadata": {
        "id": "-fsJkNQO-Vy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Files:\", len(files))\n",
        "functions = extract_functions(files)\n",
        "print(\"Functions:\", len(functions))\n",
        "df = DataFrame(functions)\n",
        "\n",
        "df.to_csv(\"corpus.csv\")"
      ],
      "metadata": {
        "id": "7Mb_cXhz-cV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2c8694-347e-4814-b809-3d9741387c3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files: 3\n",
            "Parsing\n",
            "function found\n",
            "function name: delay\n",
            "Generic found\n",
            "Parsing parameters\n",
            "Parameter found: milliseconds\n",
            "parameter type found\n",
            "Parameter found: count\n",
            "parameter type found\n",
            "End of parameters section\n",
            "Params:  milliseconds, count\n",
            "Function block\n",
            "Parsing function return type\n",
            "Function block\n",
            "function found\n",
            "function name: dramaticWelcome\n",
            "Parsing parameters\n",
            "End of parameters section\n",
            "Params:  \n",
            "Function block\n",
            "Parsing function return type\n",
            "Function block\n",
            "Parsing\n",
            "function found\n",
            "function name: initializeState\n",
            "Parsing parameters\n",
            "Parameter found: text\n",
            "parameter type found\n",
            "End of parameters section\n",
            "Params:  text\n",
            "Function block\n",
            "Parsing function return type\n",
            "Return type starts with '{'\n",
            "Function block\n",
            "Parsing\n",
            "function found\n",
            "function name: printAllChildren\n",
            "Parsing parameters\n",
            "Parameter found: node\n",
            "parameter type found\n",
            "Parameter found: depth\n",
            "Parameter found: =\n",
            "Parameter found: 0\n",
            "End of parameters section\n",
            "Params:  node, depth, =, 0\n",
            "Function block\n",
            "function found\n",
            "function name: animate\n",
            "Parsing parameters\n",
            "Parameter found: time\n",
            "parameter type found\n",
            "End of parameters section\n",
            "Params:  time\n",
            "Function block\n",
            "function found\n",
            "function name: setUpGUI\n",
            "Parsing parameters\n",
            "End of parameters section\n",
            "Params:  \n",
            "Function block\n",
            "Functions: 6\n"
          ]
        }
      ]
    }
  ]
}